{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl4r3ipUQQBh",
        "outputId": "7fc9c4cf-cb8d-483d-d1da-37ea4ff4412c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "# loading the data from csv file to Pandas DataFrame\n",
        "salesdata = pd.read_csv('/content/Train.csv')\n",
        "\n",
        "# first 5 rows of the dataframe\n",
        "print(salesdata.head())\n",
        "\n",
        "# number of data points & number of features\n",
        "salesdata.shape\n",
        "\n",
        "# getting some information about thye dataset\n",
        "salesdata.info()\n",
        "\n",
        "# checking for missing values\n",
        "salesdata.isnull().sum()\n",
        "\n",
        "# mean value of \"Item_Weight\" column\n",
        "salesdata['Item_Weight'].mean()\n",
        "\n",
        "# filling the missing values in \"Item_weight column\" with \"Mean\" value\n",
        "salesdata['Item_Weight'].fillna(salesdata['Item_Weight'].mean(), inplace=True)\n",
        "\n",
        "# mode of \"Outlet_Size\" column\n",
        "salesdata['Outlet_Size'].mode()\n",
        "\n",
        "# filling the missing values in \"Outlet_Size\" column with Mode\n",
        "outlet_size_mode = salesdata.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))\n",
        "print(outlet_size_mode)\n",
        "\n",
        "missing_values = salesdata['Outlet_Size'].isnull()\n",
        "print(missing_values)\n",
        "\n",
        "salesdata.loc[missing_values, 'Outlet_Size'] = salesdata.loc[missing_values,'Outlet_Type'].apply(lambda x: outlet_size_mode[x])\n",
        "\n",
        "# checking for missing values\n",
        "salesdata.isnull().sum()\n",
        "\n",
        "salesdata.describe()\n",
        "\n",
        "salesdata.head()\n",
        "\n",
        "salesdata['Item_Fat_Content'].value_counts()\n",
        "salesdata.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)\n",
        "salesdata['Item_Fat_Content'].value_counts()\n",
        "\n",
        "#label encoding\n",
        "encoder = LabelEncoder()\n",
        "salesdata['Item_Identifier'] = encoder.fit_transform(salesdata['Item_Identifier'])\n",
        "\n",
        "salesdata['Item_Fat_Content'] = encoder.fit_transform(salesdata['Item_Fat_Content'])\n",
        "\n",
        "salesdata['Item_Type'] = encoder.fit_transform(salesdata['Item_Type'])\n",
        "\n",
        "salesdata['Outlet_Identifier'] = encoder.fit_transform(salesdata['Outlet_Identifier'])\n",
        "\n",
        "salesdata['Outlet_Size'] = encoder.fit_transform(salesdata['Outlet_Size'])\n",
        "\n",
        "salesdata['Outlet_Location_Type'] = encoder.fit_transform(salesdata['Outlet_Location_Type'])\n",
        "\n",
        "salesdata['Outlet_Type'] = encoder.fit_transform(salesdata['Outlet_Type'])\n",
        "\n",
        "print(salesdata.head())\n",
        "\n",
        "#Splitting features and Target\n",
        "X = salesdata.drop(columns='Item_Outlet_Sales', axis=1)\n",
        "Y = salesdata['Item_Outlet_Sales']\n",
        "\n",
        "#Splitting the data into Training data & Testing Data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X.shape, X_train.shape, X_test.shape)\n",
        "\n",
        "#model training\n",
        "regressor = XGBRegressor()\n",
        "regressor.fit(X_train, Y_train)\n",
        "\n",
        "# prediction on training data\n",
        "training_data_prediction = regressor.predict(X_train)\n",
        "# R squared Value\n",
        "r2_train = metrics.r2_score(Y_train, training_data_prediction)\n",
        "print('R Squared value = ', r2_train)\n",
        "\n",
        "# prediction on test data\n",
        "test_data_prediction = regressor.predict(X_test)\n",
        "print(test_data_prediction)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Item_Identifier  Item_Weight  ...        Outlet_Type  Item_Outlet_Sales\n",
            "0           FDA15         9.30  ...  Supermarket Type1          3735.1380\n",
            "1           DRC01         5.92  ...  Supermarket Type2           443.4228\n",
            "2           FDN15        17.50  ...  Supermarket Type1          2097.2700\n",
            "3           FDX07        19.20  ...      Grocery Store           732.3800\n",
            "4           NCD19         8.93  ...  Supermarket Type1           994.7052\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8523 entries, 0 to 8522\n",
            "Data columns (total 12 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Item_Identifier            8523 non-null   object \n",
            " 1   Item_Weight                7060 non-null   float64\n",
            " 2   Item_Fat_Content           8523 non-null   object \n",
            " 3   Item_Visibility            8523 non-null   float64\n",
            " 4   Item_Type                  8523 non-null   object \n",
            " 5   Item_MRP                   8523 non-null   float64\n",
            " 6   Outlet_Identifier          8523 non-null   object \n",
            " 7   Outlet_Establishment_Year  8523 non-null   int64  \n",
            " 8   Outlet_Size                6113 non-null   object \n",
            " 9   Outlet_Location_Type       8523 non-null   object \n",
            " 10  Outlet_Type                8523 non-null   object \n",
            " 11  Item_Outlet_Sales          8523 non-null   float64\n",
            "dtypes: float64(4), int64(1), object(7)\n",
            "memory usage: 799.2+ KB\n",
            "Outlet_Type Grocery Store Supermarket Type1 Supermarket Type2 Supermarket Type3\n",
            "Outlet_Size         Small             Small            Medium            Medium\n",
            "0       False\n",
            "1       False\n",
            "2       False\n",
            "3        True\n",
            "4       False\n",
            "        ...  \n",
            "8518    False\n",
            "8519     True\n",
            "8520    False\n",
            "8521    False\n",
            "8522    False\n",
            "Name: Outlet_Size, Length: 8523, dtype: bool\n",
            "   Item_Identifier  Item_Weight  ...  Outlet_Type  Item_Outlet_Sales\n",
            "0              156         9.30  ...            1          3735.1380\n",
            "1                8         5.92  ...            2           443.4228\n",
            "2              662        17.50  ...            1          2097.2700\n",
            "3             1121        19.20  ...            0           732.3800\n",
            "4             1297         8.93  ...            1           994.7052\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "(8523, 11) (6818, 11) (1705, 11)\n",
            "[12:09:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "R Squared value =  0.6364457030941357\n",
            "[2170.391  3940.441  1354.8002 ... 2749.128  3376.4092 3868.264 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5WpQt_83j0G"
      },
      "source": [
        "\n",
        "import pickle\n",
        "pickle.dump(regressor,open('/content/model.pkl','wb'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "OtN3KEp0Z8iG",
        "outputId": "d33b70ea-79c8-4120-883f-22b30aff931b"
      },
      "source": [
        "import pickle\n",
        "import numpy as pd\n",
        "import pandas as pd\n",
        "\n",
        "model = pickle.load(open('/content/model.pkl','rb'))\n",
        "df = pd.read_csv('/content/Train.csv')\n",
        "\n",
        "\n",
        "def predict(df):\n",
        "    cols_when_model_builds = model.get_booster().feature_names\n",
        "    salesdata = df[cols_when_model_builds]\n",
        "\n",
        "    salesdata=df.iloc[:,0:-1]\n",
        "    print(salesdata)\n",
        "    salesdata.isnull().sum()\n",
        "\n",
        "    outlet_size_mode = salesdata.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))\n",
        "\n",
        "    missing_values = salesdata['Outlet_Size'].isnull()\n",
        "\n",
        "    salesdata.loc[missing_values, 'Outlet_Size'] = salesdata.loc[missing_values,'Outlet_Type'].apply(lambda x: outlet_size_mode[x])\n",
        "    salesdata['Item_Fat_Content'].value_counts()\n",
        "    salesdata.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)\n",
        "    salesdata['Item_Fat_Content'].value_counts()\n",
        "    #label encoding\n",
        "    encoder = LabelEncoder()\n",
        "    salesdata['Item_Identifier'] = encoder.fit_transform(salesdata['Item_Identifier'])\n",
        "\n",
        "    salesdata['Item_Fat_Content'] = encoder.fit_transform(salesdata['Item_Fat_Content'])\n",
        "\n",
        "    salesdata['Item_Type'] = encoder.fit_transform(salesdata['Item_Type'])\n",
        "\n",
        "    salesdata['Outlet_Identifier'] = encoder.fit_transform(salesdata['Outlet_Identifier'])\n",
        "\n",
        "    salesdata['Outlet_Size'] = encoder.fit_transform(salesdata['Outlet_Size'])\n",
        "\n",
        "    salesdata['Outlet_Location_Type'] = encoder.fit_transform(salesdata['Outlet_Location_Type'])\n",
        "\n",
        "    salesdata['Outlet_Type'] = encoder.fit_transform(salesdata['Outlet_Type'])\n",
        "    salesdata=salesdata.iloc[1:,:];\n",
        "    predictions = model.predict(np.reshape(salesdata.values.ravel(), (-1, 2)))\n",
        "    return list(predictions)\n",
        "\n",
        "print(predict(df))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12:40:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "     Item_Identifier  Item_Weight  ... Outlet_Location_Type        Outlet_Type\n",
            "0              FDA15        9.300  ...               Tier 1  Supermarket Type1\n",
            "1              DRC01        5.920  ...               Tier 3  Supermarket Type2\n",
            "2              FDN15       17.500  ...               Tier 1  Supermarket Type1\n",
            "3              FDX07       19.200  ...               Tier 3      Grocery Store\n",
            "4              NCD19        8.930  ...               Tier 3  Supermarket Type1\n",
            "...              ...          ...  ...                  ...                ...\n",
            "8518           FDF22        6.865  ...               Tier 3  Supermarket Type1\n",
            "8519           FDS36        8.380  ...               Tier 2  Supermarket Type1\n",
            "8520           NCJ29       10.600  ...               Tier 2  Supermarket Type1\n",
            "8521           FDN46        7.210  ...               Tier 3  Supermarket Type2\n",
            "8522           DRG01       14.800  ...               Tier 1  Supermarket Type1\n",
            "\n",
            "[8523 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-0dc17326a7ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-0dc17326a7ec>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msalesdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Outlet_Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Outlet_Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msalesdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalesdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility', 'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'] ['f0', 'f1']\nexpected Outlet_Type, Item_Weight, Item_MRP, Outlet_Size, Item_Visibility, Outlet_Identifier, Item_Identifier, Item_Fat_Content, Outlet_Location_Type, Outlet_Establishment_Year, Item_Type in input data\ntraining data did not have the following fields: f1, f0"
          ]
        }
      ]
    }
  ]
}